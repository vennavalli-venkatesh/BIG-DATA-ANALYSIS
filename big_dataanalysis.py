# -*- coding: utf-8 -*-
"""Big_dataanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wkk09XYVMgH8g24l3qLwqI3sDUQHZ234
"""

# step 1: Loading dataset into spark
df=spark.read.csv('/content/california_housing_train (1).csv',header=True,inferSchema=True)
# step 2: Checking for null/missing values
from pyspark.sql.functions import col, when, count
df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()
# step 3: Remove duplicates
df_cleaned = df.dropDuplicates()
df_cleaned.show(5)
# step 4: Descriptive Statistics
df_cleaned.describe().show()
# step 5: Calculate Correlation Between Features
df_cleaned.corr("median_income", "median_house_value")
# step 6: Group By and Aggregation
df_cleaned.groupBy("housing_median_age").agg({"median_house_value": "mean"}).show()
# step 7: Data visualization
# Group by 'housing_median_age' and calculate average 'median_house_value'
grouped_data = df_cleaned.groupBy("housing_median_age").avg("median_house_value").orderBy("housing_median_age")
# Convert to Pandas DataFrame
pandas_df = grouped_data.toPandas()
x = pandas_df["housing_median_age"]
y = pandas_df["avg(median_house_value)"]
import matplotlib.pyplot as plt

plt.figure(figsize=(10,5))
plt.bar(x, y)
plt.xlabel("Housing Median Age")
plt.ylabel("Average House Value")
plt.title("Average House Value by Housing Median Age")
plt.show()
# step 8: Save the cleaned data
df_cleaned.write.csv('output_file.csv', header=True)